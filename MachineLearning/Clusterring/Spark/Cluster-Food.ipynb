{"cells":[{"cell_type":"markdown","source":["<a href=\"http://www.calstatela.edu/centers/hipic\"><img align=\"left\" src=\"https://avatars2.githubusercontent.com/u/4156894?v=3&s=100\"><image/></a>\n<img align=\"right\" alt=\"California State University, Los Angeles\" src=\"http://www.calstatela.edu/sites/default/files/groups/California%20State%20University%2C%20Los%20Angeles/master_logo_full_color_horizontal_centered.svg\" style=\"width: 360px;\"/>\n\n#### Author: [Ruchi Singh](https://www.linkedin.com/in/ruchi-singh-68015945/)\n\n#### Instructor: [Jongwook Woo](https://www.linkedin.com/in/jongwook-woo-7081a85)\n\n#### Date: 05/20/2017"],"metadata":{}},{"cell_type":"markdown","source":["## Clustering\nCluster analysis divides data into groups (clusters) that are meaningful, useful or both. It describes the objects and their relationships. K-means clustering is a partitional clustering technique that attemps to find user specified numbers of cluster (K), which are representd by their centroids.\n\n## Clustering of food related business in Yelp\nGrouping food related business based on their review count, taking in account appropriate feature columns."],"metadata":{}},{"cell_type":"markdown","source":["## Download Data\n\nDownload the \"Business-Food.csv\" file and upload in Databricks. Data-> default-> Create Table. Rename the table as \"Food2\" and check for all the columns datatype. \n\nThis is the data to be used for training the machine learning algorithm."],"metadata":{}},{"cell_type":"code","source":["### Import the Libraries\nYou will use the **KMeans** class to create your model. This will require a vector of features, so you will also use the **VectorAssembler** class.\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Load Source Data\nThe source data Business-Food is a comma-separated values (CSV) file, and incldues the following features:\n- review_count: The number of reviews for the business\n- Take-out: If the food business has take facility  \n- GoodFor-lunch: The customer's think the food place is good for lunch\n- GoodFor-dinner: The customer's think the food place is good for dinner\n- GoodFor-breakfast: The customer's think the food place is good for breakfast\n- stars: The star rating given by the customers for the food business (1-5)"],"metadata":{}},{"cell_type":"code","source":["# Adopt shcmea to read csv data set in the schema. \n\ncsv = sqlContext.sql(\"Select * from food2\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":["data = csv.select(\"review_count\",\"Take-out\", \"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\",\"stars\")"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["data.show(5)"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### String Indexer\n\nStringIndexer encodes a string column of labels to a column of label indices."],"metadata":{}},{"cell_type":"code","source":["def indexStringColumns(df, cols):\n    #variable newdf will be updated several times\n    newdata = df\n    for c in cols:\n        si = StringIndexer(inputCol=c, outputCol=c+\"-x\")\n        sm = si.fit(newdata)\n        newdata = sm.transform(newdata).drop(c)\n        newdata = newdata.withColumnRenamed(c+\"-x\", c)\n    return newdata\n\ndfnumeric = indexStringColumns(data, [\"Take-out\",\"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\"])"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### Hot Encoder\n\nOne-hot encoding maps a column of label indices to a column of binary vectors, with at most a single one-value."],"metadata":{}},{"cell_type":"code","source":["def oneHotEncodeColumns(df, cols):\n    from pyspark.ml.feature import OneHotEncoder\n    newdf = df\n    for c in cols:\n        onehotenc = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n        newdf = onehotenc.transform(newdf).drop(c)\n        newdf = newdf.withColumnRenamed(c+\"-onehot\", c)\n    return newdf\n\ndfhot = oneHotEncodeColumns(dfnumeric, [\"Take-out\",\"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\"])"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["### Create the K-Means Model\nYou will use the feaures in the food business data to create a K-Means model with a k value of 5. This will be used to generate 5 clusters."],"metadata":{}},{"cell_type":"code","source":["assembler = VectorAssembler(inputCols = list(set(dfhot.columns) | set(['stars','review_count'])), outputCol=\"features\")\ntrain = assembler.transform(dfhot)\nknum = 5\nkmeans = KMeans(featuresCol=assembler.getOutputCol(), predictionCol=\"cluster\", k=knum, seed=0)\nmodel = kmeans.fit(train)\nprint \"Model Created!\""],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["### Get the Cluster Centers\nThe cluster centers are indicated as vector coordinates."],"metadata":{}},{"cell_type":"code","source":["centers = model.clusterCenters()\nprint(\"Cluster Centers: \")\nfor center in centers:\n    print(center)"],"metadata":{"collapsed":false,"scrolled":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["### Predict Clusters\nNow that we have trained the model, we can use it to segemnt the customer data into 5 clusters and show each business with their allocated cluster."],"metadata":{}},{"cell_type":"code","source":["# data set does not need to be divided to train and test\nprediction = model.transform(train)\nprediction.groupBy(\"cluster\").count().orderBy(\"cluster\").show()"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Look at the features of each cluster\n\n# define dictionary\ncustomerCluster = {}\nfor i in range(0,knum):\n    tmp = prediction.select(\"stars\",\"review_count\",\"Take-out\",\"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\")\\\n                                    .where(\"cluster =\" +  str(i))\n    customerCluster[str(i)]= tmp\n    print \"Cluster\"+str(i)\n    customerCluster[str(i)].show(3)"],"metadata":{"collapsed":false,"scrolled":true},"outputs":[],"execution_count":20}],"metadata":{"kernelspec":{"display_name":"Python 2 with Spark 2.0","language":"python","name":"python2-spark20"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"ClusterFinalBetter","notebookId":2954834256273161},"nbformat":4,"nbformat_minor":0}
