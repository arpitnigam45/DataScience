{"cells":[{"cell_type":"markdown","source":["## Logestic regression\n\nThe Logestic Regression classification model is used to predict the stars (popularity) for the business.\n\n### Prepare the Data\nFirst, import the libraries you will need and prepare the training and test data:"],"metadata":{}},{"cell_type":"code","source":["# Import Spark SQL and Spark ML libraries\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\n"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Load the source data\ncsv = sqlContext.sql(\"Select * from food2\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Select features and label\n# Logistic Regression\n# data = csv.select(\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"label\")))\ndata = csv.select(\"review_count\",\"Take-out\", \"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\",\"Noise_Level\", \"Takes_Reservations\",\"Delivery\",\"Parking_lot\", \"WheelchairAccessible\",\"Alcohol\", \"WaiterService\",\"Wi-Fi\",\"stars\")\n\n"],"metadata":{"collapsed":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":["data.show(5)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### String Indexer\nStringIndexer encodes a string column of labels to a column of label indices."],"metadata":{}},{"cell_type":"code","source":["def indexStringColumns(df, cols):\n    #variable newdf will be updated several times\n    newdata = df\n    for c in cols:\n        si = StringIndexer(inputCol=c, outputCol=c+\"-x\")\n        sm = si.fit(newdata)\n        newdata = sm.transform(newdata).drop(c)\n        newdata = newdata.withColumnRenamed(c+\"-x\", c)\n    return newdata\n\ndfnumeric = indexStringColumns(data, [\"Take-out\",\"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\",\"Noise_Level\", \"Takes_Reservations\",\"Delivery\",\"Parking_lot\", \"WheelchairAccessible\",\"Alcohol\", \"WaiterService\",\"Wi-Fi\"])\n\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["dfnumeric.show(25)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Encoder\nOne-hot encoding maps a column of label indices to a column of binary vectors, with at most a single one-value. This encoding allows algorithms which expect continuous features, in classification model, to use categorical features."],"metadata":{}},{"cell_type":"code","source":["def oneHotEncodeColumns(df, cols):\n    from pyspark.ml.feature import OneHotEncoder\n    newdf = df\n    for c in cols:\n        onehotenc = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n        newdf = onehotenc.transform(newdf).drop(c)\n        newdf = newdf.withColumnRenamed(c+\"-onehot\", c)\n    return newdf\n\ndfhot = oneHotEncodeColumns(dfnumeric, [\"Take-out\",\"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\",\"Noise_Level\", \"Takes_Reservations\",\"Delivery\",\"Parking_lot\", \"WheelchairAccessible\",\"Alcohol\", \"WaiterService\",\"Wi-Fi\"])"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["dfhot.show(25)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### Vector Assembler\nVectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression."],"metadata":{}},{"cell_type":"code","source":["va = VectorAssembler(outputCol=\"features\", inputCols=list(set(dfhot.columns)-set(['stars'])))\nlpoints = va.transform(dfhot).select(\"features\", \"stars\").withColumnRenamed(\"stars\",\"label\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Split the data\nsplits = lpoints.randomSplit([0.8, 0.2])\nadulttrain = splits[0].cache()\nadultvalid = splits[1].cache()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### Define the Pipeline\nNow define a pipeline that creates a feature vector and trains a classification model"],"metadata":{}},{"cell_type":"code","source":["lr = LogisticRegression(regParam=0.01, maxIter=1000, fitIntercept=True)\nlrmodel = lr.fit(adulttrain)\nlrmodel = lr.setParams(regParam=0.01, maxIter=500, fitIntercept=True).fit(adulttrain)\nlrmodel.intercept\n\n\nvalidpredicts = lrmodel.transform(adultvalid)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["validpredicts.show(5)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\nbceval = BinaryClassificationEvaluator()\nbceval.evaluate(validpredicts)\nbceval.getMetricName()\n\nbceval.setMetricName(\"areaUnderPR\")\nbceval.evaluate(validpredicts)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["display(validpredicts)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator\ncv = CrossValidator().setEstimator(lr).setEvaluator(bceval).setNumFolds(2)\nparamGrid = ParamGridBuilder().addGrid(lr.maxIter, [1000]).addGrid(lr.regParam, [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]).build()\ncv.setEstimatorParamMaps(paramGrid)\ncvmodel = cv.fit(adulttrain)\n\nBinaryClassificationEvaluator().evaluate(cvmodel.bestModel.transform(adultvalid))"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["### Tune Parameters\nYou can tune parameters to find the best model for your data. A simple way to do this is to use  **TrainValidationSplit** to evaluate each combination of parameters defined in a **ParameterGrid** against a subset of the training data in order to find the best performing parameters.\n\n#### Regularization \nis a way of avoiding Imbalances in the way that the data is trained against the training data so that the model ends up being over fit to the training data. In other words It works really well with the training data but it doesn't generalize well with other data.\nThat we can use a **regularization parameter** to vary the way that the model balances that way.\n\n#### Training ratio of 0.8\nit's going to use 80% of the the data that it's got in its training set to train the model and then the remaining 20% is going to use to validate the trained model. \n\nIn **ParamGridBuilder**, all possible combinations are generated from regParam, maxIter, threshold. So it is going to try each combination of the parameters with 80% of the the data to train the model and 20% to to validate it."],"metadata":{}},{"cell_type":"code","source":["# LogisticRegression with attribute 'threshold' in ParamGridBuilder and BinaryClassificationEvaluator\nparamGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.1, 0.01]).addGrid(lr.maxIter, [10, 5]).addGrid(lr.threshold, [0.35, 0.30]).build()\n\ntvs = TrainValidationSplit(estimator=lr, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\nmodel = tvs.fit(adulttrain)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### Test the Model\nNow you're ready to apply the model to the test data."],"metadata":{}},{"cell_type":"code","source":["prediction = model.transform(adultvalid)\n# LogisticRegression\npredicted = prediction.select(\"features\", \"prediction\", \"probability\", \"label\")\n\npredicted.show(100)"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["### Compute Confusion Matrix Metrics: Only for Classification Logistic Regression not for Linear Regression\nClassifiers are typically evaluated by creating a *confusion matrix*, which indicates the number of:\n- True Positives\n- True Negatives\n- False Positives\n- False Negatives\n\nFrom these core measures, other evaluation metrics such as *precision* and *recall* can be calculated.\n\n### Result\nPrecision (0.8762570727816253), Recall (0.7303376371612134): Precision becomes a little bit lower but the precision becomes much higher than previous no tuning example."],"metadata":{}},{"cell_type":"code","source":["# Only for Classification Logistic Regression not for Linear Regression\n\ntp = float(predicted.filter(\"prediction == 1.0 AND label == 1\").count())\nfp = float(predicted.filter(\"prediction == 1.0 AND label == 0\").count())\ntn = float(predicted.filter(\"prediction == 0.0 AND label == 0\").count())\nfn = float(predicted.filter(\"prediction == 0.0 AND label == 1\").count())\nmetrics = spark.createDataFrame([\n (\"TP\", tp),\n (\"FP\", fp),\n (\"TN\", tn),\n (\"FN\", fn),\n (\"Precision\", tp / (tp + fp)),\n (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\nmetrics.show()\n\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["### Review the Area Under ROC: Only for Classification Logistic Regression \nAnother way to assess the performance of a classification model is to measure the area under a ROC curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that you can use to compute this."],"metadata":{}},{"cell_type":"code","source":["display(metrics)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# LogisticRegression: rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\"\n\nevaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\naur = evaluator.evaluate(validpredicts)\nprint \"AUR = \", aur\n\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":29},{"cell_type":"code","source":[""],"metadata":{"collapsed":true},"outputs":[],"execution_count":30}],"metadata":{"kernelspec":{"display_name":"Python 2 with Spark 2.0","language":"python","name":"python2-spark20"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"Classification-Food","notebookId":2294320775048315},"nbformat":4,"nbformat_minor":0}
